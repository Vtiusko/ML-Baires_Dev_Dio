{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cd83fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from   torchvision import transforms, datasets\n",
    "import torchvision\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from   torch import nn, optim\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from   time import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e662461c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baixando as imagens e convertendo para tensor\n",
    "# Definindo a transformação de imagem para o modelo (Tensor)\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "# =====================================================================\n",
    "# =====================================================================\n",
    "trainset = datasets.MNIST( # Carregando o conjunto de dados MNIST\n",
    "    './MNIST_data/',       # Parte do treino do dataset\n",
    "    download=True,\n",
    "    train=True,\n",
    "    transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset,       # Criando o DataLoader para o conjunto de treino\n",
    "    batch_size=64,  # Cria um buffer para pegar os dados por partes\n",
    "    shuffle=True)\n",
    "\n",
    "\n",
    "# =====================================================================\n",
    "# =====================================================================\n",
    "valset = datasets.MNIST( # Carrega parte da validação do dataset\n",
    "    './MNIST_data/',\n",
    "    download=True,\n",
    "    train=False,\n",
    "    transform=transform)\n",
    "\n",
    "valloader = torch.utils.data.DataLoader(\n",
    "    valset,    # Cria um buffer para pegar os dados por partes\n",
    "    batch_size=64,\n",
    "    shuffle=False)\n",
    "\n",
    "# =====================================================================\n",
    "# =====================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cab7d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando uma imagem do treinamento\n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "imagens, labels = next(dataiter)\n",
    "\n",
    "plt.imshow(imagens[0].numpy().squeeze(), cmap='gray_r')  # Mostra a imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7949175",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(imagens[0].shape) # Para verificar as dimensões do tensor de cada imagem\n",
    "print(labels[0].shape)  # Para verificar as dimensões do label de cada imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4869f238",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copiar as camadas da rede InceptionV3\n",
    "class Modelo(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Modelo, self).__init__()  # Inicializa a classe pai\n",
    "        self.linear1 = nn. Linear(28*28, 128) # Camada de entrada, 784 neuronios que se ligan a 128\n",
    "        self.linear2 = nn. Linear(128, 64) # Camada interna 1, 128 neuronios que se ligan a 64\n",
    "        self.linear3 = nn.Linear(64, 10) # Camada interna 2, 64 neuronios que se ligam a 10\n",
    "# para a camada de saida nao e necessario definir nada pois so precisamos pegar o output da camada interna 2\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = F.relu(self.linear1(X)) # Funcão de ativacão da camada de entrada para a camada interna 1\n",
    "        X = F.relu(self.linear2(X)) # Funcao de ativacao da camada interna 1 para a camada interna 2\n",
    "        X = self.linear3(X) # Função de ativação da camada interna 2 para a camada de saida, nesse caso f(x) = x\n",
    "        return F.log_softmax(X, dim=1) # Dados utilizados para calcular a perda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb68b638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementar a parte de otimização da rede\n",
    "# onde é a primeira vista a parte de atualização dos pesos\n",
    "# para isso devemos utilizar um \"otimizador\"\n",
    "\n",
    "def treinar_modelo(modelo, trainloader, device):\n",
    "    # define a política de atualização dos pesos e da bias\n",
    "    otimizador = optim.SGD(modelo.parameters(), lr=0.01, momentum=0.5)\n",
    "    inicio = time() # Time para saber quanto tempo levou o treinamento \n",
    "\n",
    "    criterio = nn.NLLLoss() # Define o critério para calcular a perda\n",
    "    EPOCHS = 300 # Define o número de épocas para o treinamento\n",
    "    modelo.train() # Ativa o modo de treinamento do modelo\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        perda_acumulada = 0 # inicia a contagem da perda acumulada\n",
    "\n",
    "        for imagens, etiquetas in trainloader:\n",
    "            imagens = imagens.view(imagens.shape[0], -1) # Redimensiona as imagens para \"Vetores\" de 28*28 casas para ficarem compatíveis com a entrada da rede\n",
    "            otimizador.zero_grad() # Zera os gradientes do otimizador por conta do ciclo anterior\n",
    "\n",
    "            output = modelo(imagens.to(device)) # Passa as imagens pelo modelo\n",
    "            perda_instantanea = criterio(output, etiquetas.to(device)) # Calcula a perda da época em questão\n",
    "            perda_instantanea.backward() # Backpropagation à partir da perda\n",
    "\n",
    "            otimizador.step() # Atualiza os pesos do modelo e as bias\n",
    "            perda_acumulada += perda_instantanea.item() # Atualização da perda acumulada\n",
    "\n",
    "        else:\n",
    "            print(f\"Epoch {epoch+1}/{EPOCHS}, Perda: {perda_acumulada/len(trainloader)}\", end='\\n\\n')\n",
    "    print(f\"Tempo total de treinamento em minutos: {(time() - inicio) / 60} minutos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69207e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementando o modelo de validação\n",
    "# Vai nos mostrar a precisão do modelo (Acurácia)\n",
    "def validacao(modelo, valloader, device):\n",
    "    conta_corretas, conta_todas = 0, 0\n",
    "\n",
    "    for imagens,etiquetas in valloader:\n",
    "        for i in range(len(etiquetas)):\n",
    "            img = imagens[i].view(1, 784)\n",
    "\n",
    "            # Desativar o autograd para acelerar a validacao. Grafos computacionais dinâmicos tem um custo alto de processamento\n",
    "            with torch.no_grad():\n",
    "                logps = modelo(img.to(device)) # Output do modelo em escala logaritmica\n",
    "\n",
    "            ps = torch.exp(logps) # Converte output para escala normal(lembrando que é um tensor)\n",
    "            probab = list(ps.cpu().numpy()[0])\n",
    "            etiqueta_pred = probab.index(max(probab)) # Converte o tensor em um número, no caso, o número que o modelo previu como correto\n",
    "            etiqueta_certa = etiquetas.numpy()[i]\n",
    "            \n",
    "            if(etiqueta_certa == etiqueta_pred): # Compara a previsão com o valor correto\n",
    "                conta_corretas += 1\n",
    "            conta_todas += 1\n",
    "\n",
    "    print(\"Total de imagens testadas =\", conta_todas)\n",
    "    print(\"\\nPrecisão do modelo = {}%\".format(conta_corretas*100/conta_todas))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3b8b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificando se temos uma GPU disponível para treinamento\n",
    "modelo = Modelo()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "modelo.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265bf164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chamando o modelo para executar nosso treinamento e validação\n",
    "treinar_modelo(modelo, trainloader, device)\n",
    "validacao(modelo, valloader, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
